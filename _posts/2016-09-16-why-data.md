---
layout: post
title:  "Things worth keeping"
date:   2016-09-16
summary: "Science is a fantastic endeavour. And research data forms a crucial part, not just the data of the last or most brilliant experiment - but all data. Let's lay out the reasons for this again, and see whether we can do better in curating this data."
category: general
---

When highlighting scientific progress, it is convenient to put magnificent discoveries, great individual achievements and the continuing technological progress in the spotlight. But it are not these aspects that make science tick: the ability to learn from mistakes and combine contributions by many critical minds are the two key ingredients moving science ahead.
These activities can only thrive when the right boundary conditions are met, such as the right platforms to exchange ideas and filter the good from the bad ones, and the right incentives to do conduct the necessary tasks.
There is currently lot of attention to improve these boundary conditions. For example to enhance the system of scientific publication, to store and recognize more types of scientific output than only the peer-reviewed publication (like data sets, review commentaries or research proposals). 
Also the management, curation and sharing of scientific data receives considerable attention, especially data that is used in published studies. 

While all of this is good, there are reasons to take it  one step further and not only focus on the data that makes it into a published study, but rather try to curate all research data well. 

{% include image.html img="/images/long-tail.jpg" class="shadow" style="width:940px;" alt="css-theme" caption="Smaller data sets are called 'long-tail data' and the unpublished ones are named 'dark data'. The illustration shows that dark data comprises small-sized data sets .. but there are at the same time many of these. So overall dark data represent a large volume of the scientific research output." %}

Storing all data from the research process is not common practise. Too often, data that resulted from an experiment or project that failed or could not readily be interpreted is erased or lost. 

There are four reasons why we should try to improve on this point and curate more of our research data. Curating more of this data leads to:

1. better thinking
2. faster learning
3. more scientific progress
4. better rewards. 

Let's briefly explain these four points.
 
### Better thinking 
Data curation is hardly about storage. It has more to do with  scientific concepts and understanding. The process of curating research data helps us to rethink the underlying scientific questions and concepts. It also works the other way around: the better we understand a question or system that is being studied, the easier it is to unambiguously document the data and communicate it to others. 
Curating data well also forces us to think about the context of that data, the reasons of why it might be relevant beyond the original aims and ways by which it could be re-used. All of these examples would stimulate scientific spin-off while avoiding to think about these aspects would be a missed opportunity.

### Faster learning 
There is quite some research data that will never be used, e.g. because an experiment failed or some crucial contextual information is missing to interpret the data properly. Just erasing this data will not be a direct loss for science. But it could still lead to an indirect loss because it would take away the opportunity to learn from errors. So it is important to even curate erroneous research data.   
The first aspect of learning is by looking at the quantity only. The amount of erroneous data (or at least the time and effort spent in generating it) should be minimized. But we can only start to improve when information is available about the (relative) amount of erroneous data; and an effect of better working practices can only be evaluated by considering the change in the (relative) amount of erroneous data. 
A second aspect of learning is looking in more detail to the errors and would document or supply meta-data about what went wrong, in order to learn from the experience and keep it as documentation or learning material.

### More scientific progress
If (part of) a data set is not used in a current study, it might still turn-out be very useful in a subsequent study. It might be combined with other data, become part of a longitudinal series, or may provide useful information for the design-choices in subsequent research. If the data is used at any point in the future, it will have some pay-off and help to speed-up scientific developments. And curate the data well is the best chance for us to take advantage of this data in the future.

### Better rewards
Obviously we can only get credits for a research effort if there is some output. And (equally obvious) there is much more to be valued than only published peer-reviewed research papers. Fortunately, there are now plenty of opportunities to publish data sets in specialised repositories or publish a data set via a data paper. But to get to the point of publishing a data set (and be credited by getting exposure or citations through that), that data needs to be curated first.

## To conclude
So, there are several good reasons to curate research data well, even if that data seems of no direct use for a current study or when it seems is erroneous.
Curation comes at a cost, because it takes time to be systematic, to add meta-data and to and keep careful track e.g. pre-processing steps.
However, we think that the benefits greatly outweigh the cost, both at the personal level and for science in general.

At this site we are bringing together concrete information and ideas to help improving the way we take care of our data.

A longer and informative paper on the importance of curating dark data was written by P.B. Heidorn in 2008 (['Shedding Light on the Dark Data in the Long Tail of Science'](https://b2drop.eudat.eu/s/KBhRcs6lROXBF3A)). It builds on arguments that are a bit different than those put forward here and contains much more detail.
